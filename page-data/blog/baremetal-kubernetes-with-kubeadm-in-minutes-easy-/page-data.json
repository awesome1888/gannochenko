{"componentChunkName":"component---src-components-blog-page-layout-blog-page-layout-tsx","path":"/blog/baremetal-kubernetes-with-kubeadm-in-minutes-easy-","result":{"data":{"mdx":{"id":"a5dfe91d-e937-580f-891a-33a608c78293","body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"Baremetal Kubernetes with kubeadm in 10 minutes? Easy!\",\n  \"description\": \"A while ago, being on sick leave, I challenged myself with setting up a baremetal K8s cluster. I chose Kubeadm back then, and so now I am sharing the results.\",\n  \"keywords\": \"kubernetes, devops, kubeadm, baremetal, infrastructure\",\n  \"path\": \"/blog/baremetal-kubernetes-with-kubeadm-in-minutes-easy-\",\n  \"date\": \"2020-10-23T00:00:00.000Z\",\n  \"published\": true,\n  \"images\": [{\n    \"author\": \"Toni Vuohelainen\",\n    \"image\": \"./cover.jpg\",\n    \"sourceText\": \"Flickr\",\n    \"source\": \"https://www.flickr.com/photos/tonivuohelainen/\",\n    \"is_cover\": 1,\n    \"galleryId\": 0\n  }]\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"p\", null, \"A while ago, being on sick leave, I challenged myself with setting up a baremetal K8s cluster. I chose \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"Kubeadm\"), \" back then, and so now I am sharing the results.\"), mdx(\"p\", null, \"Yeh, maybe you already have the following question popped up in your mind:\"), mdx(\"p\", null, mdx(\"span\", {\n    parentName: \"p\",\n    \"className\": \"gatsby-resp-image-wrapper\",\n    \"style\": {\n      \"position\": \"relative\",\n      \"display\": \"block\",\n      \"marginLeft\": \"auto\",\n      \"marginRight\": \"auto\",\n      \"maxWidth\": \"888px\"\n    }\n  }, \"\\n      \", mdx(\"a\", {\n    parentName: \"span\",\n    \"className\": \"gatsby-resp-image-link\",\n    \"href\": \"/static/23361d302162a070a9b889a096ae8b83/bf093/why-the-hell.jpg\",\n    \"style\": {\n      \"display\": \"block\"\n    },\n    \"target\": \"_blank\",\n    \"rel\": \"noopener\"\n  }, \"\\n    \", mdx(\"span\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-background-image\",\n    \"style\": {\n      \"paddingBottom\": \"56.37065637065637%\",\n      \"position\": \"relative\",\n      \"bottom\": \"0\",\n      \"left\": \"0\",\n      \"backgroundImage\": \"url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAALABQDASIAAhEBAxEB/8QAGAAAAwEBAAAAAAAAAAAAAAAAAAMFAgT/xAAVAQEBAAAAAAAAAAAAAAAAAAABAv/aAAwDAQACEAMQAAABiu6tzU0WJ//EABkQAAIDAQAAAAAAAAAAAAAAAAECAAMRMv/aAAgBAQABBQLSsZzsqANaIut1/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAGhAAAgIDAAAAAAAAAAAAAAAAAAECIRExMv/aAAgBAQAGPwKmYUjaJUcoZ//EABsQAQACAgMAAAAAAAAAAAAAAAEAESFBobHR/9oACAEBAAE/IRCsaaibikzbEL7Ycoc7J4BOZP/aAAwDAQACAAMAAAAQg8//xAAXEQADAQAAAAAAAAAAAAAAAAAAARFB/9oACAEDAQE/EJhUf//EABcRAAMBAAAAAAAAAAAAAAAAAAABETH/2gAIAQIBAT8QWUh//8QAHRABAAMAAgMBAAAAAAAAAAAAAQARIVFhMUGhsf/aAAgBAQABPxAGmoiruvkPU3om2aRaogwL3BBx6jxGt1PGeZpu37P/2Q==')\",\n      \"backgroundSize\": \"cover\",\n      \"display\": \"block\"\n    }\n  }), \"\\n  \", mdx(\"img\", {\n    parentName: \"a\",\n    \"className\": \"gatsby-resp-image-image\",\n    \"alt\": \"Why the hell\",\n    \"title\": \"Why the hell\",\n    \"src\": \"/static/23361d302162a070a9b889a096ae8b83/bf093/why-the-hell.jpg\",\n    \"srcSet\": [\"/static/23361d302162a070a9b889a096ae8b83/8356d/why-the-hell.jpg 259w\", \"/static/23361d302162a070a9b889a096ae8b83/bc760/why-the-hell.jpg 518w\", \"/static/23361d302162a070a9b889a096ae8b83/bf093/why-the-hell.jpg 888w\"],\n    \"sizes\": \"(max-width: 888px) 100vw, 888px\",\n    \"style\": {\n      \"width\": \"100%\",\n      \"height\": \"100%\",\n      \"margin\": \"0\",\n      \"verticalAlign\": \"middle\",\n      \"position\": \"absolute\",\n      \"top\": \"0\",\n      \"left\": \"0\"\n    },\n    \"loading\": \"lazy\"\n  }), \"\\n  \"), \"\\n    \")), mdx(\"p\", null, \"Well, you may want to consider a bare-metal cluster, because\"), mdx(\"p\", null, \"\\uD83D\\uDC49 you are setting up an internal infrastructure for your company, and using cloud providers is not an option,\", mdx(\"br\", null), \"\\n\\uD83D\\uDC49 you wish to receive close-to-production experience with you own pet K8s,\", mdx(\"br\", null), \"\\n\\uD83D\\uDC49 you are well-aware of Minikube, MicroK8s and others, but always wanted to have a real multi-node cluster out there,\", mdx(\"br\", null), \"\\n\\uD83D\\uDC49 you don't want to pay for a pre-configured AKS/GKE/EKS/whatever solution just yet,\", mdx(\"br\", null), \"\\n\\uD83D\\uDC49 you want to set everything up from scratch, at least once, out of curiosity,\", mdx(\"br\", null), \"\\n\\uD83D\\uDC49 you have free time :)\", mdx(\"br\", null)), mdx(\"p\", null, \"Why making another article while there is plenty of them already? Well because most of the material is obviously not for beginners.\\nSometimes the material feels fragmented, ripped ouf of the context of something bigger or simply not covering the entire process.\"), mdx(\"p\", null, \"What you should understand just before we continue.\"), mdx(\"p\", null, \"\\u261D\\uFE0F It still won't be a production-ready environment for mature projects! \\uD83D\\uDEA8\\uD83D\\uDEA8\\uD83D\\uDEA8\", mdx(\"br\", null), \"\\n\\u261D\\uFE0F However, with extra hours dedicated, the cluster can become production-ready.\", mdx(\"br\", null), \"\\n\\u261D\\uFE0F But even so, it will be good enough for hobby projects, proof of concepts, learning and exploration.\", mdx(\"br\", null), \"\\n\\u261D\\uFE0F You will not receive any GUI control panel, only raw \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"kubectl\"), \".\", mdx(\"br\", null)), mdx(\"p\", null, \"Resonates with your needs? Then let's do it!\"), mdx(\"h2\", null, \"Nodes\"), mdx(\"p\", null, \"Kubernetes is a \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"cluster\"), \", it means that typically more than one machine is involved.\\nI got for myself two instances of VDS (VPS), with 2 Cores and 4 GB of RAM each (those are the minimum requirements), Centos7 on-board. It was a cheap russian hosting with a data center in Moscow and unlimited bandwidth.\\nIt works for me just fine, but you can pick AWS's EC2, DigitalOcean or Vultr, or any other provider.\"), mdx(\"p\", null, \"You may as well get two virtual machines with VirtualBox and Vagrant, but it will not give you the same experience.\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"X.X.X.X\"), \" - IP address of Node A\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"Y.Y.Y.Y\"), \" - IP address of Node B\")), mdx(\"p\", null, \"Just as a part of pre-flight preparations, I run the following commands to make the whole process a bit easier.\"), mdx(\"p\", null, \"On my machine:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-bash\"\n  }, \"printf \\\"\\\\nX.X.X.X k8s-master\\\\nY.Y.Y.Y k8s-node01\\\\n\\\" | sudo tee -a /etc/hosts;\\nscp ~/.ssh/id_rsa.pub root@X.X.X.X:~\\nscp ~/.ssh/id_rsa.pub root@Y.Y.Y.Y:~\\n\")), mdx(\"p\", null, \"On each node under \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"root\"), \":\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-bash\",\n    \"metastring\": \"bashRoot\",\n    \"bashRoot\": true\n  }, \"yum update\\n\\n# create a non-root user\\nuseradd admin\\n\\n# enable sudo\\nusermod -aG wheel admin\\npasswd admin\\npasswd -l admin\\n\\n# enable key-based sign-in\\ncd /home/admin/\\nmkdir ./.ssh\\nchmod 711 ./.ssh\\ncat ~/id_rsa.pub >> ./.ssh/authorized_keys\\nchmod 600 ./.ssh/authorized_keys\\nchown -R admin:admin ./.ssh\\n\")), mdx(\"p\", null, \"You may also want to disable password-based SSH authentication, disable root login and switch SSH to a different port to ward off brute-forcers.\"), mdx(\"p\", null, \"Now I can sign-in the nodes by typing \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"ssh admin@k8s-node01\"), \" without password and able to run \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"sudo\"), \".\"), mdx(\"h2\", null, \"Common setup\"), mdx(\"p\", null, \"Kubernetes logically consists of two parts: \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"Control plane\"), \" and \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"Compute\"), \".\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"Control plane\"), \" operates the cluster, and it is hosted on so-called \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"master node(s)\"), \".\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"Compute\"), \" runs containerized applications and is hosted on \", mdx(\"inlineCode\", {\n    parentName: \"li\"\n  }, \"worker nodes\"), \".\")), mdx(\"p\", null, \"Therefore, I choose \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"Node A\"), \" to be the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"master node\"), \", whereas \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"Node B\"), \" - \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"worker node\"), \".\"), mdx(\"p\", null, \"The following set of commands I need to run \", mdx(\"ins\", null, \"on each node\"), \":\"), mdx(\"p\", null, \"\\u27A1\\uFE0F Allow nodes to address each other by name:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-bash\"\n  }, \"printf \\\"\\\\nX.X.X.X master\\\\nY.Y.Y.Y node01\\\\n\\\" | sudo tee -a /etc/hosts;\\n\")), mdx(\"p\", null, \"Make sure nodes can actually talk to each other:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-bash\"\n  }, \"ping master\\nping node01\\n\")), mdx(\"p\", null, \"\\u27A1\\uFE0F K8s does not play nicely with SELinux, switching it off:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-bash\"\n  }, \"sudo setenforce 0\\nsudo sed -i --follow-symlinks 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/sysconfig/selinux\\n\")), mdx(\"p\", null, \"\\u27A1\\uFE0F K8s uses \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"br_netfilter\"), \" kernel module for it's internal networking. So I check if module even exists, load it, and enable on-boot load: \"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-bash\"\n  }, \"sudo modprobe br_netfilter\\nsudo echo \\\"br_netfilter\\\" | sudo tee -a /etc/modules-load.d/br_netfilter.conf\\n\")), mdx(\"p\", null, \"\\u27A1\\uFE0F Tell the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"bridge module\"), \" to use \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"iptables\"), \":\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-bash\"\n  }, \"echo '1' | sudo tee -a /proc/sys/net/bridge/bridge-nf-call-iptables\\nprintf \\\"\\\\nnet.bridge.bridge-nf-call-iptables = 1\\\\nnet.ipv4.ip_forward=1\\\\n\\\" | sudo tee -a /etc/sysctl.conf\\nsudo sysctl -p\\n\")), mdx(\"p\", null, \"\\u27A1\\uFE0F Disable firewalld \\uD83D\\uDC7B \\uD83D\\uDE31\"), mdx(\"p\", null, \"Some out-of-the-box firewall rules are set in a way it paralyzes cluster networking. In production it totally makes sense to find what causes that and fix the issue. Since I am building a non-production environment, I don't bother investing time. So I just disable \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"firewalld\"), \" and by doing so I wipe out all firewall rules.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-bash\"\n  }, \"sudo systemctl stop firewalld\\nsudo systemctl disable firewalld\\nsudo systemctl mask --now firewalld\\n\\n# making sure there is not a single rule left, and the policy is \\\"ACCEPT\\\" on every chain\\nsudo iptables -L -v -n\\n\")), mdx(\"p\", null, \"\\u27A1\\uFE0F K8s requires the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"swap\"), \" partition to be disabled for good:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-bash\"\n  }, \"sudo swapoff -a\\nsudo sed -i '/ swap / s/^\\\\(.*\\\\)$/#\\\\1/g' /etc/fstab;\\n\")), mdx(\"p\", null, \"\\u27A1\\uFE0F Install and configure \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"Docker\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-bash\"\n  }, \"sudo yum install -y yum-utils device-mapper-persistent-data lvm2\\nsudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo\\nsudo yum install -y docker-ce\\n\\n# changing docker cgroupdriver to \\\"systemd\\\" \\nsudo mkdir /etc/docker\\nsudo tee /etc/docker/daemon.json > /dev/null <<'EOF'\\n{\\n  \\\"exec-opts\\\": [\\\"native.cgroupdriver=systemd\\\"],\\n  \\\"log-driver\\\": \\\"json-file\\\",\\n  \\\"log-opts\\\": {\\n    \\\"max-size\\\": \\\"100m\\\"\\n  },\\n  \\\"storage-driver\\\": \\\"overlay2\\\",\\n  \\\"storage-opts\\\": [\\n    \\\"overlay2.override_kernel_check=true\\\"\\n  ]\\n}\\nEOF\\n\")), mdx(\"p\", null, \"\\u27A1\\uFE0F Install \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"kubelet\"), \", \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"kubectl\"), \" and \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"kubeadm\")), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-bash\"\n  }, \"sudo tee /etc/yum.repos.d/kubernetes.repo > /dev/null <<'EOF'\\n[kubernetes]\\nname=Kubernetes\\nbaseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64\\nenabled=1\\ngpgcheck=1\\nrepo_gpgcheck=1\\ngpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg\\n        https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg\\nEOF\\n\\nsudo yum install -y kubelet kubeadm kubectl\\n\")), mdx(\"p\", null, \"\\u27A1\\uFE0F Launch \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"Docker\"), \" daemon\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-bash\"\n  }, \"sudo systemctl start docker\\nsudo systemctl enable docker\\n\")), mdx(\"p\", null, \"\\u27A1\\uFE0F Launch \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"Kubelet\"), \" daemon\"), mdx(\"p\", null, \"Kubeled daemon in charge of doing all K8s-related stuff on this particular node.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-bash\"\n  }, \"sudo systemctl start kubelet\\nsudo systemctl enable kubelet\\n\")), mdx(\"p\", null, \"Allright, hopefully no errors there, and we can proceed to more neat stuff.\"), mdx(\"h2\", null, \"Master-specific setup\"), mdx(\"p\", null, \"The commands below should be executed \", mdx(\"ins\", null, \"on the master node only\"), \".\"), mdx(\"p\", null, \"\\u27A1\\uFE0F Let \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"kubeadm\"), \" do all the heavy lifting:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-bash\"\n  }, \"sudo kubeadm init --apiserver-advertise-address=X.X.X.X --pod-network-cidr=10.244.0.0/16 --apiserver-cert-extra-sans=localhost,127.0.0.1\\n\")), mdx(\"p\", null, \"If everything went well, I just need to do a few more extra steps.\"), mdx(\"p\", null, \"\\u27A1\\uFE0F Create a configuration file for the current user (admin)\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-bash\"\n  }, \"mkdir -p ${HOME}/.kube\\nsudo cp -i /etc/kubernetes/admin.conf ${HOME}/.kube/config\\nsudo chown $(id -u):$(id -g) ${HOME}/.kube/config\\n\")), mdx(\"p\", null, \"\\u27A1\\uFE0F Deploy a pod network\"), mdx(\"p\", null, \"So we have containers. A \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"container\"), \" is a containerized application written in any language (Node, Java, Go, ...) and running inside of the cluster.\\nA \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"pod\"), \" is a group of \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"containers\"), \", which share common resources.\\n\", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"Pods\"), \" are exposed to the outer world via \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"services\"), \".\"), mdx(\"p\", null, \"Yeh, sounds complicated. But this is what makes K8s quite abstracted and therefore unbiased and flexible.\"), mdx(\"p\", null, \"So the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"pod network\"), \" then is an implementation of K8s networking model: it enables pods talking to each other, to services, and via services - to the outer world.\"), mdx(\"p\", null, \"There are numerous implementations out there, but I will stick to the kinda default one, which is called \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"flannel\"), \". It is basic and proven to be working.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-bash\"\n  }, \"kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml\\n\")), mdx(\"h2\", null, \"Joining the nodes\"), mdx(\"p\", null, \"Hooray! Technically nothing stops us from joining the nodes together now.\"), mdx(\"p\", null, \"On the master node I create a new token for joining the cluster:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-bash\"\n  }, \"sudo kubeadm token create\\n\")), mdx(\"p\", null, \"This will get me the token of format \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"xxxxxx.xxxxxxxxxxxxxxxx\"), \".\"), mdx(\"h2\", null, \"Worker-specific setup\"), mdx(\"p\", null, \"The commands below should be executed \", mdx(\"ins\", null, \"on the worker node(s) only\"), \".\"), mdx(\"p\", null, \"\\u27A1\\uFE0F Add a worker node to the cluster\"), mdx(\"p\", null, \"Member that token I made? I need that one to execute the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"join\"), \" command \", mdx(\"ins\", null, \"on each worker node\"), \":\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-bash\"\n  }, \"sudo kubeadm join X.X.X.X:6443 --token xxxxxx.xxxxxxxxxxxxxxxx --discovery-token-unsafe-skip-ca-verification\\n\")), mdx(\"p\", null, \"From this moment on, there will be no need to do something else on the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"worker\"), \" node, so I may end that ssh session.\"), mdx(\"h2\", null, \"Checking the status of the cluster\"), mdx(\"p\", null, \"I can now go back to the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"master\"), \" node and check how the cluster is doing:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-bash\"\n  }, \"kubectl get nodes\\n\")), mdx(\"p\", null, \"If I see something like this...\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-text\"\n  }, \"NAME     STATUS   ROLES    AGE    VERSION\\nnode01   Ready    <none>   4h7m   v1.19.3\\nmaster   Ready    master   45h    v1.19.3\\n\")), mdx(\"p\", null, \"... that means: \\\"Congratulations \\uD83C\\uDF89\\uD83C\\uDF89\\uD83C\\uDF89 You and I just got our own K8s clusters up and running!\\\" \"), mdx(\"p\", null, \"Most of the tutorials usually end here, or they maybe show how to expose an Apache container via a \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"NodePort\"), \"-type service (make a container accessible on the worker node directly via a random port greater than 1023). This obviously is not commonly-used IRL, as it defeats one of the key advantages of K8s. So instead let's go a bit further and setup \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"ingress\"), \". \"), mdx(\"p\", null, \"\\u27A1\\uFE0F Ingress\"), mdx(\"p\", null, \"Basically, ingress tells the cluster \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"\\xAB\", \"Hey, for this given domain, path and protocol route all requests to the service A. For other domain, path and protocol - to the service B (and so on)\", \"\\xBB\"), \". So ingress works as a router for the incoming requests.\"), mdx(\"p\", null, \"Sounds quite powerful, doesn't it? I am gonna use \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"ingress-nginx\"), \", the default kubernetes ingress, as it is pretty simple and easily configurable:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-bash\"\n  }, \"kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v0.40.2/deploy/static/provider/baremetal/deploy.yaml\\n\")), mdx(\"p\", null, \"Let's check how ingress is doing:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-bash\"\n  }, \"kubectl get pods -n ingress-nginx\\n\")), mdx(\"p\", null, \"In a few minutes, the status should look somewhat like this:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-text\"\n  }, \"NAME                                        READY   STATUS      RESTARTS   AGE\\ningress-nginx-admission-create-7dhcj        0/1     Completed   0          22m\\ningress-nginx-admission-patch-kcsvt         0/1     Completed   0          22m\\ningress-nginx-controller-785557f9c9-7ldcl   1/1     Running     0          22m\\n\")), mdx(\"p\", null, \"\\u27A1\\uFE0F Load balancer\"), mdx(\"p\", null, \"What ingress does not know, obviously, is how exactly the cluster is connected to the outer world. This task is solved by a \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"load balancer\"), \" that typically works outside of the cluster. Every cloud provider implements it's own one, and their load balancers vary from one to another. Since I don't have any cloud provider here, I need a substitution.\"), mdx(\"p\", null, \"So there is a project called \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"Metallb\"), \", which I am going to leverage for this matter. Please find which version is \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://metallb.universe.tf/\"\n  }, \"the latest\"), \". Also, sometimes they do backward-incompatible installation instruction updates, so if something does not work, feel free to \", mdx(\"a\", {\n    parentName: \"p\",\n    \"href\": \"https://metallb.universe.tf/installation/\"\n  }, \"check their docs out\"), \"!\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-bash\"\n  }, \"kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.9.4/manifests/namespace.yaml\\nkubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.9.4/manifests/metallb.yaml\\nkubectl create secret generic -n metallb-system memberlist --from-literal=secretkey=\\\"$(openssl rand -base64 128)\\\"\\n\")), mdx(\"p\", null, \"I also need to provide a config file, otherwise the balancer stays dormant.\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-bash\"\n  }, \"tee /tmp/metallb-conf.yml > /dev/null <<'EOF'\\napiVersion: v1\\nkind: ConfigMap\\nmetadata:\\n    namespace: metallb-system\\n    name: config\\ndata:\\n    config: |\\n        address-pools:\\n        - name: default\\n          protocol: layer2\\n          addresses:\\n          - Y.Y.Y.Y\\nEOF\\nkubectl apply -f /tmp/metallb-conf.yml;\\nrm /tmp/metallb-conf.yml;\\n\")), mdx(\"p\", null, \"To see how the balancer is doing:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-bash\"\n  }, \"kubectl get pods -n metallb-system\\n\")), mdx(\"p\", null, \"It should look like this:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-text\"\n  }, \"NAME                         READY   STATUS    RESTARTS   AGE\\ncontroller-8687cdc65-h6d5m   1/1     Running   0          14s\\nspeaker-b4p95                1/1     Running   0          14s\\nspeaker-xhm72                1/1     Running   0          14s\\n\")), mdx(\"hr\", null), mdx(\"p\", null, \"Okay, so this is pretty it. I have set the cluster up, and it is working. In the next article (which is coming soon) I will deploy an infrastructure using Terraform, with actual domains and SSL support! Stay tuned.\"), mdx(\"h2\", null, \"Troubleshooting\"), mdx(\"h3\", null, \"\\uD83D\\uDC49\\uD83D\\uDC1B When joining a new node, the process hangs at the \\\"\", \"[preflight]\", \" Running pre-flight checks\\\" stage forever.\"), mdx(\"p\", null, \"Endless process or timeout error sometimes lie in the I/O plane. Please make sure that nodes can ping each other by IP and the \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"master\"), \" node has only kubelet-produced rules in \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"iptables\"), \".\"), mdx(\"h3\", null, \"\\uD83D\\uDC49\\uD83D\\uDC1B Pods are stuck at \\\"ContainerCreating\\\" step\"), mdx(\"p\", null, \"This problem may have many causes. In general, to see the events of a pod and where it stuck, a \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"describe pods\"), \" command is used:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-bash\"\n  }, \"kubectl describe pods -n ingress-nginx\\n\")), mdx(\"p\", null, \"If something goes totally pear-shaped, you may consider running the following piece of commands \", mdx(\"ins\", null, \"on each node\"), \" to revert the cluster to pre \", mdx(\"inlineCode\", {\n    parentName: \"p\"\n  }, \"kubectl init (join)\"), \" state:\"), mdx(\"pre\", null, mdx(\"code\", {\n    parentName: \"pre\",\n    \"className\": \"language-bash\"\n  }, \"sudo kubeadm reset -f\\nsudo rm -rf /etc/cni/net.d\\n\\nsudo iptables -P INPUT ACCEPT\\nsudo iptables -P FORWARD ACCEPT\\nsudo iptables -P OUTPUT ACCEPT\\nsudo iptables -t nat -F\\nsudo iptables -t mangle -F\\nsudo iptables -F\\nsudo iptables -X\\n\\nsudo systemctl restart docker\\nsudo systemctl restart kubelet\\n\\nrm -rf ${HOME}/.kube\\n\")), mdx(\"h2\", null, \"Useful links\"), mdx(\"ul\", null, mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/\"\n  }, \"kubeadm\"), \" - K8s's official bootstrapping tool\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://kops.sigs.k8s.io/\"\n  }, \"kops\"), \" - K8s installer on AWS/GCE/OpenStack/Digital Ocean/Spot Ocean\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://kubespray.io/\"\n  }, \"kubespray\"), \" - another installer\"), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://rancher.com/\"\n  }, \"rancher\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://kubernetes.io/docs/reference/kubectl/cheatsheet/\"\n  }, \"k8s cheatsheet\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://kubernetes.io/docs/concepts/cluster-administration/networking/\"\n  }, \"list of pod networks in the alphabetical order\")), mdx(\"li\", {\n    parentName: \"ul\"\n  }, mdx(\"a\", {\n    parentName: \"li\",\n    \"href\": \"https://medium.com/flant-com/comparing-ingress-controllers-for-kubernetes-9b397483b46b\"\n  }, \"list of ingress controllers\"))));\n}\n;\nMDXContent.isMDXComponent = true;","frontmatter":{"title":"Baremetal Kubernetes with kubeadm in 10 minutes? Easy!","date":"2020-10-23T00:00:00.000Z","updatedAt":null,"keywords":"kubernetes, devops, kubeadm, baremetal, infrastructure","description":"A while ago, being on sick leave, I challenged myself with setting up a baremetal K8s cluster. I chose Kubeadm back then, and so now I am sharing the results.","published":true,"images":[{"image":{"childImageSharp":{"fluid":{"tracedSVG":"data:image/svg+xml,%3csvg%20xmlns='http://www.w3.org/2000/svg'%20width='400'%20height='265'%20viewBox='0%200%20400%20265'%20preserveAspectRatio='none'%3e%3cpath%20d='M0%2098c0%2097%200%2098%202%2098l2-1h2c-1-2%202-4%203-4v-1h1c1%201%201%201%201-1l2-1c2%200%202%200%201-1-2-1-2-1%200-1%202%201%204%200%2017-10l4-3%208-5%208-5%2013-9%203-1%207-4c7-4%2013-6%2012-4l1%204c1%203%200%206-2%206l-8%206-3%202-2%201h-3l-1%201-1%201-2%201-3%201c-4%200-8%203-8%207-1%203-2%204-4%201h-3l-5%205a140%20140%200%2000-13%2011c-8%205-15%2011-16%2013-1%203-2%204-4%202l-2%201-2%202c-1-1-2%200-3%201v2l2%202H1c-1-1-1%203-1%208%200%207%200%209%201%207l5-5a429%20429%200%200146-36c-3%201-2%200%202-2l4-3%206-3%2011-5a345%20345%200%200138-19l7-4h4c1-2%202-2%203-2%201%201%203%200%204-1l3-1h2c2%200%202%200%201-1-3-1-1-3%203-4l3%201%202%201%201-1%202-2%2014-3%206-2%206-2%2010-1%209-2%2010-1c13-1%2022-3%2023-4h4c7%200%2018-2%2019-3h1a514%20514%200%2001135%2020l3-8%202-8-1-2-1%202c-1%202-1%203-2%202l-4%201c-1%201-1%201-1-1h-8l-5-1h-4l-1-2-2-1-4-1h-8c-2-2-1-3%201-2h2c-1-1-1-1%201-1l2-1h-7l-8-1h-3c-1%200-2%200-1-1%203-1-1-4-4-3l-15%201c-11%200-12%200-13-2-1-3-11-3-10%200l-1%201-3-2a640%20640%200%2001-26-2c-4%203-7%203-6%202l-2-1h-4l-5%201h-11l-3%202-4%201c-1-1-2%200-2%201s-1%201-2-1v-2h-3l-11%201h-12l-4%201-1%201c-1%200-2%201-2%203%200%205-3%205-4%201h-7l-3%201-4%201-1%201h-1l-3-1c-2%200-3%200-2%201%201%202-3%202-5%201-1-1-1-1-1%201%201%202-2%204-4%202h-6c-4-2-4-2-4%200l-2-2-6-15c0-1-5-7-7-7l-1-1c0-1-5-3-12-4l-6-1c7-4%207-5%205-7l-6-10-3-4-3-5-1-1h-1l-1-3v-2l-1-4-2-4-1-2v-2l-1-2-1-4-1-6c-2-3-4-11-4-15l-1-2-3-7-4-10-1-4V4l-1-2c-1-3-3-3-3%200l-1%202-2-2c0-2-1-2-38-2H0v98M93%204l1%205%202%205%202%209%204%2012c7%2022%209%2028%2017%2038l8%2013%205%209c3%203%207%209%207%2011l2%204%202%204c0%206%202%207%2010%203l5-1%204-1c1-1%203-2%204-1l3-1%208-1%209-3%2010-2h11a211%20211%200%200131-5%20615%20615%200%2001112%207l4%201h1c0-2%200-2%202-1h3c1-1%203%200%207%201l7%202%202%201h2l2%201%202%201h2l2%202%203%201%204-4c7-10%207-5%207-62V0H92l1%204m304%20119l-3%208-1%203c-2%201-4%205-4%207l-1%202c-3%202-2%203%203%204l6%203%203%201v-35l-3%207m-129%208v8a572%20572%200%2001-24%203c-2%202-2%202-3%200h-10a441%20441%200%2001-33%204l-12%202-4%201-9%203-9%203-2%201a200%20200%200%2000-48%2017%2091%2091%200%2001-15%206l-18%2010-10%206c-1%201-2%202-3%201l-1%201-5%204a301%20301%200%2000-39%2027l-1%201c0%201-5%206-7%206l-1%202h-2l-3%201-3%202c-2%201-2%201%200%201%203%200%203%200%202%202l-3%201-2%201c1%201%200%203-1%204-2%201-2%203-2%209v7h401l-1-50-1-51-6-2-8-3-5-1-4-2h-3l-1-1-2-1-3-1-1-1-5-1-14-2-3-1-1-1h-2l-2-1c-3%200-7-2-8-3h-10l-4%201-4-2a326%20326%200%2001-30-3h-1l-4-1h-4l1-1%201-1h-2l-2-1c0-1%201-2%203-2h2l1%201v-3l-1-1-3%201h-3c-2-2-3-2-3%200'%20fill='%23d3d3d3'%20fill-rule='evenodd'/%3e%3c/svg%3e","aspectRatio":1.5121951219512195,"src":"/static/0e5daa328c28f0de81a813ba6795696d/77467/cover.jpg","srcSet":"/static/0e5daa328c28f0de81a813ba6795696d/dece2/cover.jpg 310w,\n/static/0e5daa328c28f0de81a813ba6795696d/fcb16/cover.jpg 620w,\n/static/0e5daa328c28f0de81a813ba6795696d/77467/cover.jpg 1240w,\n/static/0e5daa328c28f0de81a813ba6795696d/b1020/cover.jpg 1860w,\n/static/0e5daa328c28f0de81a813ba6795696d/c0737/cover.jpg 2047w","sizes":"(max-width: 1240px) 100vw, 1240px"}}},"author":"Toni Vuohelainen","source":"https://www.flickr.com/photos/tonivuohelainen/","sourceText":"Flickr","is_cover":1,"galleryId":0}]}}},"pageContext":{"id":"a5dfe91d-e937-580f-891a-33a608c78293"}},"staticQueryHashes":["1334184578","1334184578","2277278352","2277278352","400101895","400101895"]}